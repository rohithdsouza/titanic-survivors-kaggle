{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a80714d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-30T12:07:02.417227Z",
     "iopub.status.busy": "2021-07-30T12:07:02.416362Z",
     "iopub.status.idle": "2021-07-30T12:07:02.421386Z",
     "shell.execute_reply": "2021-07-30T12:07:02.422121Z",
     "shell.execute_reply.started": "2021-07-30T11:04:16.373349Z"
    },
    "papermill": {
     "duration": 0.027557,
     "end_time": "2021-07-30T12:07:02.422493",
     "exception": false,
     "start_time": "2021-07-30T12:07:02.394936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7a703",
   "metadata": {
    "papermill": {
     "duration": 0.006162,
     "end_time": "2021-07-30T12:07:02.436401",
     "exception": false,
     "start_time": "2021-07-30T12:07:02.430239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading the training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9235d13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-30T12:07:02.454188Z",
     "iopub.status.busy": "2021-07-30T12:07:02.453444Z",
     "iopub.status.idle": "2021-07-30T12:07:02.577667Z",
     "shell.execute_reply": "2021-07-30T12:07:02.577137Z",
     "shell.execute_reply.started": "2021-07-30T11:13:38.193823Z"
    },
    "papermill": {
     "duration": 0.135134,
     "end_time": "2021-07-30T12:07:02.577820",
     "exception": false,
     "start_time": "2021-07-30T12:07:02.442686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "train_data.head()\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e00314",
   "metadata": {
    "papermill": {
     "duration": 0.006405,
     "end_time": "2021-07-30T12:07:02.590836",
     "exception": false,
     "start_time": "2021-07-30T12:07:02.584431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading Test dataset\n",
    "As we can notice, the number of columns is one less from _train_data_ meaning the **\"Survived\"** column is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eae67b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-30T12:07:02.608711Z",
     "iopub.status.busy": "2021-07-30T12:07:02.608063Z",
     "iopub.status.idle": "2021-07-30T12:07:02.628234Z",
     "shell.execute_reply": "2021-07-30T12:07:02.627584Z",
     "shell.execute_reply.started": "2021-07-30T11:13:29.858948Z"
    },
    "papermill": {
     "duration": 0.031052,
     "end_time": "2021-07-30T12:07:02.628368",
     "exception": false,
     "start_time": "2021-07-30T12:07:02.597316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "test_data.head()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5130b4",
   "metadata": {
    "papermill": {
     "duration": 0.006776,
     "end_time": "2021-07-30T12:07:02.641909",
     "exception": false,
     "start_time": "2021-07-30T12:07:02.635133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Implementing Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ab6fc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-30T12:07:02.665205Z",
     "iopub.status.busy": "2021-07-30T12:07:02.664529Z",
     "iopub.status.idle": "2021-07-30T12:07:04.251192Z",
     "shell.execute_reply": "2021-07-30T12:07:04.250363Z",
     "shell.execute_reply.started": "2021-07-30T12:06:01.680770Z"
    },
    "papermill": {
     "duration": 1.602374,
     "end_time": "2021-07-30T12:07:04.251336",
     "exception": false,
     "start_time": "2021-07-30T12:07:02.648962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8282828282828283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "#features taken for consideration\n",
    "features = [\"Pclass\",\"Sex\",\"SibSp\",\"Parch\", \"Embarked\",\"Fare\"] \n",
    "\n",
    "#pre-process\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "\n",
    "#getting the input for our model\n",
    "x = pd.get_dummies(train_data[features])\n",
    "x_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "imp.fit(x)\n",
    "x_clean = imp.transform(x) \n",
    "x_test_clean = imp.transform(x_test)\n",
    "\n",
    "\n",
    "#defining our model\n",
    "model = RandomForestClassifier(n_estimators = 100, max_depth = 5\n",
    "                              , random_state = 1)\n",
    "\n",
    "#linking i/p and expected o/p r prediction for our model for training\n",
    "model.fit(x_clean ,y)\n",
    "\n",
    "##return a list of predictions for test data\n",
    "predictions = model.predict(x_test_clean)\n",
    "\n",
    "#create a o/p dataframe\n",
    "output = pd.DataFrame ({'PassengerId' : test_data.PassengerId , \n",
    "                       'Survived' : predictions })\n",
    "\n",
    "#save as a csv for submission\n",
    "output.to_csv(\"my_submission.csv\",index=False)\n",
    "\n",
    "#return a list of predictions for training data (testing accuracy)\n",
    "y_predict = model.predict(x_clean)\n",
    "print(accuracy_score(y , y_predict))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.56982,
   "end_time": "2021-07-30T12:07:04.968484",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-30T12:06:54.398664",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
